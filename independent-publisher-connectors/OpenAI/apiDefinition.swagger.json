{
  "swagger": "2.0",
  "info": {
    "title": "OpenAI",
    "description": "Connect to the OpenAI API and use the Power of ChatGPT, Dall-E and more",
    "version": "2.0",
    "contact": {
      "name": "Robin Rosengr√ºn",
      "url": "https://linktr.ee/r2power",
      "email": "robin@r2power.de"
    }
  },
  "host": "api.openai.com",
  "basePath": "/",
  "schemes": [
    "https"
  ],
  "consumes": [],
  "produces": [],
  "paths": {
    "/v1/chat/completions": {
      "post": {
        "responses": {
          "200": {
            "description": "default",
            "schema": {
              "type": "object",
              "properties": {
                "id": {
                  "type": "string",
                  "description": "A unique identifier for the chat completion."
                },
                "object": {
                  "type": "string",
                  "description": "The object type, which is always chat.completion."
                },
                "created": {
                  "type": "integer",
                  "format": "int32",
                  "description": "The Unix timestamp (in seconds) of when the chat completion was created."
                },
                "choices": {
                  "type": "array",
                  "items": {
                    "type": "object",
                    "properties": {
                      "index": {
                        "type": "integer",
                        "format": "int32",
                        "description": "The index of the choice in the list of choices."
                      },
                      "message": {
                        "type": "object",
                        "properties": {
                          "role": {
                            "type": "string",
                            "description": "The role of the author of this message."
                          },
                          "content": {
                            "type": "string",
                            "description": "The contents of the message."
                          },
                          "tool_calls": {
                            "type": "array",
                            "items": {
                              "type": "object",
                              "properties": {
                                "id": {
                                  "type": "string",
                                  "description": "The ID of the tool call."
                                },
                                "type": {
                                  "type": "string",
                                  "description": "The type of the tool. Currently, only function is supported."
                                },
                                "function": {
                                  "type": "object",
                                  "properties": {
                                    "name": {
                                      "type": "string",
                                      "description": "The name of the function to call."
                                    },
                                    "arguments": {
                                      "type": "string",
                                      "description": "The arguments to call the function with, as generated by the model in JSON format. Note that the model does not always generate valid JSON, and may hallucinate parameters not defined by your function schema. Validate the arguments in your code before calling your function."
                                    }
                                  },
                                  "description": "The function that the model called."
                                }
                              }
                            },
                            "description": "The tool calls generated by the model, such as function calls."
                          }
                        },
                        "description": "A chat completion message generated by the model"
                      },
                      "finish_reason": {
                        "type": "string",
                        "description": "The reason the model stopped generating tokens. This will be stop if the model hit a natural stop point or a provided stop sequence, length if the maximum number of tokens specified in the request was reached, content_filter if content was omitted due to a flag from our content filters, tool_calls if the model called a tool, or function_call (deprecated) if the model called a function."
                      }
                    }
                  },
                  "description": "A list of chat completion choices. Can be more than one if n is greater than 1."
                },
                "first_choice": {
                  "type": "object",
                  "properties": {
                    "finish_reason": {
                      "type": "string",
                      "description": "finish_reason"
                    },
                    "index": {
                      "type": "integer",
                      "format": "int32",
                      "description": "index"
                    },
                    "message": {
                      "type": "object",
                      "properties": {
                        "role": {
                          "type": "string",
                          "description": "The role of the author of this message."
                        },
                        "content": {
                          "type": "string",
                          "description": "The contents of the message."
                        },
                        "tool_calls": {
                          "type": "array",
                          "items": {
                            "type": "object",
                            "properties": {
                              "id": {
                                "type": "string",
                                "description": "id"
                              },
                              "type": {
                                "type": "string",
                                "description": "The type of the tool. Currently, only function is supported."
                              },
                              "function": {
                                "type": "object",
                                "properties": {
                                  "name": {
                                    "type": "string",
                                    "description": "The name of the function to call."
                                  },
                                  "arguments": {
                                    "type": "string",
                                    "description": "The arguments to call the function with, as generated by the model in JSON format. Note that the model does not always generate valid JSON, and may hallucinate parameters not defined by your function schema. Validate the arguments in your code before calling your function."
                                  }
                                },
                                "description": "The function that the model called."
                              }
                            }
                          },
                          "description": "The tool calls generated by the model, such as function calls."
                        }
                      },
                      "description": "message"
                    }
                  },
                  "description": "First object of the choices array for easier handling in Power Apps and Automate"
                },
                "first_content": {
                  "type": "string",
                  "description": "Content string in the first choices object for easier handling in Power Apps and Automate (this is basically the reply from GPT)"
                },
                "usage": {
                  "type": "object",
                  "properties": {
                    "prompt_tokens": {
                      "type": "integer",
                      "format": "int32",
                      "description": "Number of tokens in the prompt."
                    },
                    "completion_tokens": {
                      "type": "integer",
                      "format": "int32",
                      "description": "Number of tokens in the generated completion."
                    },
                    "total_tokens": {
                      "type": "integer",
                      "format": "int32",
                      "description": "Total number of tokens used in the request (prompt + completion)."
                    }
                  },
                  "description": "Usage statistics for the completion request."
                }
              }
            }
          }
        },
        "summary": "Chat Completion",
        "operationId": "ChatCompletion",
        "description": "Use models like ChatGPT and GPT4 to hold a conversation",
        "x-ms-visibility": "important",
        "parameters": [
          {
            "name": "body",
            "in": "body",
            "required": false,
            "schema": {
              "type": "object",
              "properties": {
                "model": {
                  "type": "string",
                  "description": "The used model, choose between gpt-3.5-turbo, gpt-4 and others",
                  "default": "gpt-3.5-turbo"
                },
                "messages": {
                  "type": "array",
                  "items": {
                    "type": "object",
                    "properties": {
                      "role": {
                        "type": "string",
                        "description": "The role of the author of this message. One of system, user, or assistant.",
                        "enum": [
                          "user",
                          "system",
                          "assistant"
                        ]
                      },
                      "content": {
                        "type": "string",
                        "description": "The contents of the message."
                      }
                    },
                    "required": [
                      "role",
                      "content"
                    ]
                  },
                  "description": "messages"
                },
                "messagesAsString": {
                  "type": "string",
                  "description": "messages json as string - overrides messages, if you want to use the vision functionality in Power Apps, use JSON() to generate it from a "
                },
                "n": {
                  "type": "integer",
                  "format": "int32",
                  "description": "How many completions to generate for each prompt",
                  "default": 1
                },
                "temperature": {
                  "type": "number",
                  "format": "float",
                  "description": "Higher values means the model will take more risks. Try 0.9 for more creative applications, and 0 (argmax sampling) for ones with a well-defined answer. Use this OR top p",
                  "title": "temperature",
                  "default": 0.5
                },
                "max_tokens": {
                  "type": "integer",
                  "format": "int32",
                  "description": "One token equals roughly 4 characters of text (up to 4000 or more tokens between prompt and completion, depending on model)",
                  "title": "max tokens"
                },
                "top_p": {
                  "type": "number",
                  "format": "float",
                  "description": "An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.",
                  "title": "top p"
                },
                "frequency_penalty": {
                  "type": "number",
                  "format": "float",
                  "description": "Number between -2.0 and 2.0. Positive values penalize new tokens based on their existing frequency in the text so far, decreasing the models likelihood to repeat the same line verbatim.",
                  "title": "frequency penalty",
                  "default": 0
                },
                "presence_penalty": {
                  "type": "number",
                  "format": "float",
                  "description": "Number between -2.0 and 2.0. Positive values penalize new tokens based on whether they appear in the text so far, increasing the models likelihood to talk about new topics.",
                  "title": "presence penalty",
                  "default": 0
                },
                "stop": {
                  "type": "array",
                  "items": {
                    "type": "string"
                  },
                  "description": "Up to 4 sequences where the API will stop generating further tokens. The returned text will not contain the stop sequence"
                }
              },
              "required": [
                "model",
                "messages"
              ]
            }
          }
        ]
      }
    },
    "/v1/embeddings": {
      "post": {
        "responses": {
          "200": {
            "description": "default",
            "schema": {
              "type": "object",
              "properties": {
                "object": {
                  "type": "string",
                  "description": "object"
                },
                "data": {
                  "type": "array",
                  "items": {
                    "type": "object",
                    "properties": {
                      "object": {
                        "type": "string",
                        "description": "The object type, which is always \"embedding\"."
                      },
                      "embedding": {
                        "type": "array",
                        "items": {
                          "type": "number",
                          "format": "float"
                        },
                        "description": "Represents an embedding vector"
                      },
                      "index": {
                        "type": "integer",
                        "format": "int32",
                        "description": "The index of the embedding in the list of embeddings."
                      }
                    }
                  },
                  "description": "data"
                },
                "model": {
                  "type": "string",
                  "description": "ID of the model to use"
                },
                "usage": {
                  "type": "object",
                  "properties": {
                    "prompt_tokens": {
                      "type": "integer",
                      "format": "int32",
                      "description": "prompt_tokens"
                    },
                    "total_tokens": {
                      "type": "integer",
                      "format": "int32",
                      "description": "total_tokens"
                    }
                  },
                  "description": "usage"
                }
              }
            }
          }
        },
        "summary": "Embeddings",
        "description": "Get a vector representation of a given input",
        "operationId": "Embeddings",
        "parameters": [
          {
            "name": "body",
            "in": "body",
            "required": false,
            "schema": {
              "type": "object",
              "properties": {
                "model": {
                  "type": "string",
                  "description": "model",
                  "default": "text-embedding-ada-002"
                },
                "input": {
                  "type": "string",
                  "description": "Input text to embed, encoded as a string or array of tokens. To embed multiple inputs in a single request, pass an array of strings or array of token arrays. The input must not exceed the max input tokens for the model"
                }
              },
              "required": [
                "input",
                "model"
              ]
            }
          }
        ]
      }
    },
    "/v1/images/generations": {
      "post": {
        "responses": {
          "200": {
            "description": "default",
            "schema": {
              "type": "object",
              "properties": {
                "created": {
                  "type": "integer",
                  "format": "int32",
                  "description": "Unique Creation ID from OpenAI",
                  "title": "created",
                  "x-ms-visibility": "internal"
                },
                "data": {
                  "type": "array",
                  "items": {
                    "type": "object",
                    "properties": {
                      "revised_prompt": {
                        "type": "string",
                        "description": "The prompt that was used to generate the image, if there was any revision to the prompt."
                      },
                      "url": {
                        "type": "string",
                        "description": "URL to created Image",
                        "title": "url"
                      },
                      "b64_json": {
                        "type": "string",
                        "description": "Image in base64 format",
                        "title": "base64image",
                        "format": "byte"
                      }
                    }
                  },
                  "description": "data"
                }
              }
            }
          }
        },
        "summary": "Create an Image",
        "operationId": "CreateImage",
        "parameters": [
          {
            "name": "body",
            "in": "body",
            "required": false,
            "schema": {
              "type": "object",
              "properties": {
                "prompt": {
                  "type": "string",
                  "description": "A text description of the desired image(s). The maximum length is 1000 characters for dall-e-2 and 4000 characters for dall-e-3.",
                  "title": "prompt",
                  "default": "An elephant with a fedora in a dark room, digital art"
                },
                "model": {
                  "type": "string",
                  "description": "The used dall-e model (2 or 3)",
                  "title": "model",
                  "default": "dall-e-2",
                  "enum": [
                    "dall-e-2",
                    "dall-e-3"
                  ]
                },
                "n": {
                  "type": "integer",
                  "format": "int32",
                  "description": "The number of images to generate. Must be between 1 and 10. For dall-e-3, only n=1 is supported.",
                  "title": "Number of images",
                  "default": 1
                },
                "size": {
                  "type": "string",
                  "title": "size",
                  "description": "The size of the generated images. 256x256, 512x512 or 1024x1024 for dall-e-2, 1024x1024, 1792x1024 or 1024x1792 for dall-e-3",
                  "enum": [
                    "256x256",
                    "512x512",
                    "1024x1024",
                    "1792x1024",
                    "1024x1792"
                  ],
                  "default": "1024x1024"
                },
                "response_format": {
                  "type": "string",
                  "title": "format",
                  "description": "Get url to picture or receive it in base64 format (default: url)",
                  "enum": [
                    "url",
                    "b64_json"
                  ],
                  "default": "url"
                },
                "quality": {
                  "type": "string",
                  "title": "quality",
                  "description": "The quality of the image that will be generated. hd creates images with finer details and greater consistency across the image. This param is only supported for dall-e-3."
                },
                "style": {
                  "type": "string",
                  "title": "style",
                  "description": "The style of the generated images. Must be one of vivid or natural. Vivid causes the model to lean towards generating hyper-real and dramatic images. Natural causes the model to produce more natural, less hyper-real looking images. This param is only supported for dall-e-3.",
                  "enum": [
                    "vivid",
                    "natural"
                  ],
                  "default": "vivid"
                }
              },
              "required": [
                "prompt"
              ]
            }
          }
        ],
        "description": "DallE creates an image from your prompt"
      }
    },
    "/v1/audio/speech": {
      "post": {
        "responses": {
          "200": {
            "description": "default",
            "schema": {
              "type": "string",
              "description": "audio",
              "format": "binary"
            }
          }
        },
        "summary": "Create Speech",
        "description": "Generates audio from the input text",
        "operationId": "CreateSpeech",
        "parameters": [
          {
            "name": "body",
            "in": "body",
            "required": false,
            "schema": {
              "type": "object",
              "properties": {
                "model": {
                  "type": "string",
                  "description": "One of the available TTS models tts-1 or tts-1-hd",
                  "default": "tts-1"
                },
                "input": {
                  "type": "string",
                  "description": "The text to generate audio for. The maximum length is 4096 characters.",
                  "default": "The quick brown fox jumped over the lazy dog."
                },
                "voice": {
                  "type": "string",
                  "description": "The voice to use when generating the audio. Supported voices are alloy, echo, fable, onyx, nova, and shimmer",
                  "default": "alloy",
                  "enum": [
                    "alloy",
                    "echo",
                    "fable",
                    "onyx",
                    "nova",
                    "shimmer"
                  ]
                },
                "response_format": {
                  "type": "string",
                  "description": "The format to audio in. Supported formats are mp3, opus, aac, and flac.",
                  "default": "mp3",
                  "enum": [
                    "mp3",
                    "opus",
                    "aac",
                    "flac"
                  ]
                },
                "speed": {
                  "type": "number",
                  "description": "The speed of the generated audio. Select a value from 0.25 to 4.0. 1.0 is the default",
                  "default": 1
                }
              },
              "required": [
                "model",
                "input",
                "voice"
              ]
            }
          }
        ]
      }
    },
    "/v1/audio/transcriptions": {
      "post": {
        "responses": {
          "default": {
            "description": "default",
            "schema": {
              "type": "object",
              "properties": {
                "text": {
                  "type": "string",
                  "description": "The transcribed text."
                }
              }
            }
          }
        },
        "summary": "Speech to Text",
        "operationId": "Speech2Text",
        "consumes": [
          "multipart/form-data"
        ],
        "parameters": [
          {
            "name": "Content-Type",
            "in": "header",
            "required": false,
            "type": "string"
          },
          {
            "name": "file",
            "in": "formData",
            "type": "file",
            "required": true
          },
          {
            "name": "filename",
            "in": "formData",
            "type": "string",
            "required": true
          },
          {
            "name": "model",
            "in": "formData",
            "type": "string",
            "required": true
          }
        ]
      }
    }
  },
  "definitions": {},
  "parameters": {},
  "responses": {},
  "securityDefinitions": {
    "API Key": {
      "type": "apiKey",
      "in": "header",
      "name": "Authorization"
    }
  },
  "security": [
    {
      "API Key": []
    }
  ],
  "tags": [],
  "x-ms-connector-metadata": [
    {
      "propertyName": "Website",
      "propertyValue": "https://openai.com/"
    },
    {
      "propertyName": "Privacy policy",
      "propertyValue": "https://openai.com/api/policies/terms/"
    },
    {
      "propertyName": "Categories",
      "propertyValue": "AI"
    }
  ]
}
